# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2026-01-29

## reinforcement learning
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Enabling SSI-Compliant Use of EUDI Wallet Credentials through Trusted Execution Environment and Zero-Knowledge Proof](https://arxiv.org/abs/2601.19893v1)** | 2026-01-27 | <details><summary>Show</summary><p>The passing of the eIDAS amendment marks an important milestone for EU countries and changes how they must manage digital credentials for both public services and businesses. Italy has led in adopting eIDAS, first with CIE and SPID identity schemes, and now with the Italian Wallet (IO app) aligned to eIDAS 2.0. Self-Sovereign Identity (SSI) is a decentralized model born from the success of Distributed Ledgers, giving individuals full control over their digital identity. The current eIDAS 2.0 and its implementation acts diverge from SSI principles, rendering the European Digital Identity Wallet (EUDIW) centralized and merely user-centric, prioritizing security and legal protection over true self-sovereignty. This paper proposes an architecture that enables the use of IT Wallet credentials and services in an SSI-compliant environment through Trusted Execution Environments and Zero-Knowledge Proofs.</p></details> |  |
| **[Self-Sovereign Identity and eIDAS 2.0: An Analysis of Control, Privacy, and Legal Implications](https://arxiv.org/abs/2601.19837v1)** | 2026-01-27 | <details><summary>Show</summary><p>European digital identity initiatives are grounded in regulatory frameworks designed to ensure interoperability and robust, harmonized security standards. The evolution of these frameworks culminates in eIDAS 2.0, whose origins trace back to the Electronic Signatures Directive 1999/93/EC, the first EU-wide legal foundation for the use of electronic signatures in cross-border electronic transactions. As technological capabilities advanced, the initial eIDAS 1.0 framework was increasingly criticized for its limitations and lack of comprehensiveness. Emerging decentralized approaches further exposed these shortcomings and introduced the possibility of integrating innovative identity paradigms, such as Self-Sovereign Identity (SSI) models. In this article, we analyse key provisions of the eIDAS 2.0 Regulation and its accompanying recitals, drawing on existing literature to identify legislative gaps and implementation challenges. Furthermore, we examine the European Digital Identity Architecture and Reference Framework (ARF), assessing its proposed guidelines and evaluating the extent to which its emerging implementations align with SSI principles.</p></details> |  |
| **[Knowledge-Aware Evolution for Streaming Federated Continual Learning with Category Overlap and without Task Identifiers](https://arxiv.org/abs/2601.19788v1)** | 2026-01-27 | <details><summary>Show</summary><p>Federated Continual Learning (FCL) leverages inter-client collaboration to balance new knowledge acquisition and prior knowledge retention in non-stationary data. However, existing batch-based FCL methods lack adaptability to streaming scenarios featuring category overlap between old and new data and absent task identifiers, leading to indistinguishability of old and new knowledge, uncertain task assignments for samples, and knowledge confusion.To address this, we propose streaming federated continual learning setting: per federated learning (FL) round, clients process streaming data with disjoint samples and potentially overlapping categories without task identifiers, necessitating sustained inference capability for all prior categories after each FL round.Next, we introduce FedKACE: 1) an adaptive inference model switching mechanism that enables unidirectional switching from local model to global model to achieve a trade-off between personalization and generalization; 2) a adaptive gradient-balanced replay scheme that reconciles new knowledge learning and old knowledge retention under overlapping-class scenarios; 3) a kernel spectral boundary buffer maintenance that preserves high-information and high-boundary-influence samples to optimize cross-round knowledge retention. Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE.</p></details> |  |
| **[Accelerating radio astronomy imaging with RICK: a step towards SKA-Mid and SKA-Low](https://arxiv.org/abs/2601.19714v1)** | 2026-01-27 | <details><summary>Show</summary><p>The data volumes generated by modern radio interferometers, such as the SKA precursors, present significant computational challenges for imaging pipelines. Addressing the need for high-performance, portable, and scalable software, we present RICK 2.0 (Radio Imaging Code Kernels). This work introduces a novel implementation that leverages the HeFFTe library for distributed Fast Fourier Transforms, ensuring portability across diverse HPC architectures, including multi-core CPUs and accelerators. We validate RICK's correctness and performance against real observational data from both MeerKAT and LOFAR. Our results demonstrate that the HeFFTe-based implementation offers substantial performance advantages, particularly when running on GPUs, and scales effectively with large pixel resolutions and a high number of frequency planes. This new architecture overcomes the critical scaling limitations identified in previous work (Paper II, Paper III), where communication overheads consumed up to 96% of the runtime due to the necessity of communicating the entire grid. This new RICK version drastically reduces this communication impact, representing a scalable and efficient imaging solution ready for the SKA era.</p></details> | <details><summary>29 pa...</summary><p>29 pages, 8 figures, Accepted for publication on Astronomy and Computing Journal</p></details> |
| **[MSCCL++: Rethinking GPU Communication Abstractions for AI Inference](https://arxiv.org/abs/2504.09014v4)** | 2026-01-27 | <details><summary>Show</summary><p>AI applications increasingly run on fast-evolving, heterogeneous hardware to maximize performance, but general-purpose libraries lag in supporting these features. Performance-minded programmers often build custom communication stacks that are fast but error-prone and non-portable. This paper introduces MSCCL++, a design methodology for developing high-performance, portable communication kernels. It provides (1) a low-level, performance-preserving primitive interface that exposes minimal hardware abstractions while hiding the complexities of synchronization and consistency, (2) a higher-level DSL for application developers to implement workload-specific communication algorithms, and (3) a library of efficient algorithms implementing the standard collective API, enabling adoption by users with minimal expertise. Compared to state-of-the-art baselines, MSCCL++ achieves geomean speedups of $1.7\times$ (up to $5.4\times$) for collective communication and $1.2\times$ (up to $1.38\times$) for AI inference workloads. MSCCL++ is in production of multiple AI services provided by Microsoft Azure, and has also been adopted by RCCL, the GPU collective communication library maintained by AMD. MSCCL++ is open source and available at https://github.com/microsoft/mscclpp . Our two years of experience with MSCCL++ suggests that its abstractions are robust, enabling support for new hardware features, such as multimem, within weeks of development.</p></details> | 15 pages, 13 figures |
| **[Parallel Spawning Strategies for Dynamic-Aware MPI Applications](https://arxiv.org/abs/2511.04268v2)** | 2026-01-27 | <details><summary>Show</summary><p>Dynamic resource management is an increasingly important capability of High Performance Computing systems, as it enables jobs to adjust their resource allocation at runtime. This capability can reduce workload makespan, substantially decreasing job waiting times and optimizing resource allocation. In this context, malleability refers to the ability of applications to adapt to new resource allocations during execution. Although beneficial, malleability incurs significant reconfiguration costs, making the reduction of these costs an important research topic. Some existing solutions for MPI applications respawn the entire application, which is an expensive solution that avoids the reuse of original processes. Other MPI solutions reuse them, but fail to fully release unneeded processes when shrinking, since some ranks within the same communicator remain active across nodes, preventing the application from returning those nodes to the system. This work overcomes both limitations by proposing a novel parallel spawning strategy, in which all processes cooperate in the spawning. This allows expansions to reuse processes while also terminating unneeded ones. This strategy has been validated on two systems with either machines with equal or different numbers of cores. Experiments show that this strategy preserves competitive expansion times with at most a $1.13\times$ and $1.25\times$ overhead for equal and different number of cores per node, respectively. More importantly, it enables fast shrink operations that reduce their cost by at least $1387\times$ and $20\times$ in the same scenarios.</p></details> | <details><summary>14 pa...</summary><p>14 pages, 2 Tables, 6 Figures, 9 Equations, 4 Listings</p></details> |
| **[Minimmit: Fast Finality with Even Faster Blocks](https://arxiv.org/abs/2508.10862v7)** | 2026-01-27 | <details><summary>Show</summary><p>Achieving low-latency consensus in geographically distributed systems remains a key challenge for blockchain and distributed database applications. To this end, there has been significant recent interest in State-Machine-Replication (SMR) protocols that achieve 2-round finality under the assumption that $5f+1\leq n$, where $n$ is the number of processors and $f$ bounds the number of processors that may exhibit Byzantine faults. In these protocols, instructions are organised into views, each led by a different designated leader, and 2-round finality means that a leader's proposal can be finalised after just a single round of voting, meaning two rounds overall (one round for the proposal and one for voting). We introduce Minimmit, a Byzantine-fault-tolerant SMR protocol with lower latency than previous 2-round finality approaches. Our key insight is that view progression and transaction finality can operate on different quorum thresholds without compromising safety or liveness. Experiments simulating a globally distributed network of 50 processors, uniformly assigned across ten virtual regions, show that the approach leads to a 23.1% reduction in view latency and a 10.7% reduction in transaction latency compared to the state-of-the-art.</p></details> |  |
| **[Convex Hull 3D Filtering with GPU Ray Tracing and Tensor Cores](https://arxiv.org/abs/2601.19647v1)** | 2026-01-27 | <details><summary>Show</summary><p>In recent years, applications such as real-time simulations, autonomous systems, and video games increasingly demand the processing of complex geometric models under stringent time constraints. Traditional geometric algorithms, including the convex hull, are subject to these challenges. A common approach to improve performance is scaling computational resources, which often results in higher energy consumption. Given the growing global concern regarding sustainable use of energy, this becomes a critical limitation. This work presents a 3D preprocessing filter for the convex hull algorithm using ray tracing and tensor core technologies. The filter builds a delimiter polyhedron based on Manhattan distances that discards points from the original set. The filter is evaluated on two point distributions: uniform and sphere. Experimental results show that the proposed filter, combined with convex hull construction, accelerates the computation of the 3D convex hull by up to $200 \times$ with respect to a CPU parallel implementation. This research demonstrates that geometric algorithms can be accelerated through massive parallelism while maintaining efficient energy utilization. Beyond execution time and speedup evaluation, we also analyze GPU energy consumption, showing that the proposed preprocessing filter not only reduces the computational workload but also achieves performance gains with controlled energy usage. These results highlight the dual benefit of the method in terms of both speed and energy efficiency, reinforcing its applicability in modern high-performance scenarios.</p></details> |  |
| **[Modular Foundation Model Inference at the Edge: Network-Aware Microservice Optimization](https://arxiv.org/abs/2601.19563v1)** | 2026-01-27 | <details><summary>Show</summary><p>Foundation models (FMs) unlock unprecedented multimodal and multitask intelligence, yet their cloud-centric deployment precludes real-time responsiveness and compromises user privacy. Meanwhile, monolithic execution at the edge remains infeasible under stringent resource limits and uncertain network dynamics. To bridge this gap, we propose a microservice-based FM inference framework that exploits the intrinsic functional asymmetry between heavyweight core services and agile light services. Our two-tier deployment strategy ensures robust Quality of Service (QoS) under resource contention. Specifically, core services are placed statically via a long-term network-aware integer program with sparsity constraints to form a fault-tolerant backbone. On the other hand, light services are orchestrated dynamically by a low-complexity online controller that integrates effective capacity theory with Lyapunov optimization, providing probabilistic latency guarantees under real-time workload fluctuations. Simulations demonstrate that our framework achieves over 84% average on-time task completion with moderate deployment costs and maintains strong robustness as the system load scales.</p></details> | <details><summary>4 fig...</summary><p>4 figures. Conference</p></details> |
| **[Rule-Based Graph Programs Matching the Time Complexity of Imperative Algorithms](https://arxiv.org/abs/2501.09144v4)** | 2026-01-27 | <details><summary>Show</summary><p>We report on recent advances in rule-based graph programming, which allow us to match the time complexity of some fundamental imperative graph algorithms. In general, achieving the time complexity of graph algorithms implemented in conventional languages using a rule-based graph-transformation language is challenging due to the cost of graph matching. Previous work demonstrated that with rooted rules, certain algorithms can be implemented in the graph programming language GP 2 such that their runtime matches the time complexity of imperative implementations. However, this required input graphs to have a bounded node degree and (for some algorithms) to be connected. In this paper, we overcome these limitations by enhancing the graph data structure generated by the GP 2 compiler and exploiting the new structure in programs. We present three case studies: the first program checks whether input graphs are connected, the second program checks whether input graphs are acyclic, and the third program solves the single-source shortest-paths problem for graphs with integer edge-weights. The first two programs run in linear time on (possibly disconnected) input graphs with arbitrary node degrees. The third program runs in time $O(nm)$ on arbitrary input graphs, matching the time complexity of imperative implementations of the Bellman-Ford algorithm. For each program, we formally prove its correctness and time complexity, and provide runtime experiments on various graph classes.</p></details> | LMCS |
| **[Optimizing FaaS Platforms for MCP-enabled Agentic Workflows](https://arxiv.org/abs/2601.14735v2)** | 2026-01-27 | <details><summary>Show</summary><p>Agentic workflows that use autonomous AI Agents powered by Large Language Models (LLMs) and Model Context Protocol (MCP) servers is rapidly rising. This introduces challenges in scalable cloud deployment and state management. Traditional hosting on Virtual Machines (VMs) is resource-intensive and lacks elasticity. Functions-as-a-Service (FaaS) platforms offer modularity, autoscaling and cost efficiency but are inherently stateless. In this paper, we present the FAME, a FaaS-based architecture for orchestrating MCP-enabled agentic workflows. FAME decomposes agentic patterns such as ReAct into composable agents: Planner, Actor and Evaluator, that are each a FaaS function built using LangGraph and are orchestrated as a FaaS workflow. This enables modular composition as AWS Step Functions and avoids function timeouts seen for monolithic agentic workflows. To address context persistence across user requests in a conversation, FAME automates agent memory persistence and injection using DynamoDB. It also optimizes MCP server deployment through AWS Lambda wrappers, caches tool outputs in S3 and proposes function fusion strategies. We evaluate FAME on two representative applications, on research paper summarization and log analytics, under diverse memory and caching configurations. Results show up to 13x latency reduction, 88% fewer input tokens and 66% in cost savings, along with improved workflow completion rates. This demonstrates the viability of serverless platforms for hosting complex, multi-agent AI workflows at scale.</p></details> |  |
| **[For Generalised Algebraic Theories, Two Sorts Are Enough](https://arxiv.org/abs/2601.19426v1)** | 2026-01-27 | <details><summary>Show</summary><p>Generalised algebraic theories (GATs) allow multiple sorts indexed over each other. For example, the theories of categories or Martin-L{ö}f type theories form GATs. Categories have two sorts, objects and morphisms, and the latter are double-indexed over the former. Martin-L{ö}f type theory has four sorts: contexts, substitutions, types and terms. For example, types are indexed over contexts, and terms are indexed over both contexts and types. In this paper we show that any GAT can be reduced to a GAT with only two sorts, and there is a section-retraction correspondence (formally, a strict coreflection) between models of the original and the reduced GAT. In particular, any model of the original GAT can be turned into a model of the reduced (two-sorted) GAT and back, and this roundtrip is the identity. The reduced GAT is simpler than the original GAT in the following aspects: it does not have sort equalities; it does not have interleaved sorts and operations; if the original GAT did not have interleaved sorts and operations, then the reduced GAT won't have operations interleaved between different sorts. In a type-theoretic metatheory, the initial algebra of a GAT is called a quotient inductive-inductive type (QIIT). Our reduction provides a way to implement QIITs with sort equalities or interleaved constructors which are not allowed by Cubical Agda. An instance of our reduction is the well-known method of reducing mutual inductive types to a single indexed family. Our approach is semantic in that it does not rely on a syntactic description of GATs, but instead, on Uemura's bi-initial characterisation of the category of (finite) GATs in the 2-category of finitely complete categories with a chosen exponentiable morphism.</p></details> |  |
| **[Specifying and Verifying RDMA Synchronisation (Extended Version)](https://arxiv.org/abs/2601.14642v2)** | 2026-01-27 | <details><summary>Show</summary><p>Remote direct memory access (RDMA) allows a machine to directly read from and write to the memory of remote machine, enabling high-throughput, low-latency data transfer. Ensuring correctness of RDMA programs has only recently become possible with the formalisation of $\text{RDMA}^\text{TSO}$ semantics (describing the behaviour of RDMA networking over a TSO CPU). However, this semantics currently lacks a formalisation of remote synchronisation, meaning that the implementations of common abstractions such as locks cannot be verified. In this paper, we close this gap by presenting $\text{RDMA}^{\text{TSO}}_{\text{RMW}}$, the first semantics for remote `read-modify-write' (RMW) instructions over TSO. It turns out that remote RMW operations are weak and only ensure atomicity against other remote RMWs. We therefore build a set of composable synchronisation abstractions starting with the $\text{RDMA}^{\text{WAIT}}_{\text{RMW}}$ library. Underpinned by $\text{RDMA}^{\text{WAIT}}_{\text{RMW}}$, we then specify, implement and verify three classes of remote locks that are suitable for different scenarios. Additionally, we develop the notion of a strong RDMA model, $\text{RDMA}^{\text{SC}}_{\text{RMW}}$, which is akin to sequential consistency in shared memory architectures. Our libraries are built to be compatible with an existing set of high-performance libraries called LOCO, which ensures compositionality and verifiability.</p></details> | <details><summary>95 pa...</summary><p>95 pages, extended version of ESOP 2026 paper, replaced to fix a tikz opacity problem</p></details> |
| **[Decentralized Nonsmooth Nonconvex Optimization with Client Sampling](https://arxiv.org/abs/2601.19381v1)** | 2026-01-27 | <details><summary>Show</summary><p>This paper considers decentralized nonsmooth nonconvex optimization problem with Lipschitz continuous local functions. We propose an efficient stochastic first-order method with client sampling, achieving the $(δ,ε)$-Goldstein stationary point with the overall sample complexity of ${\mathcal O}(δ^{-1}ε^{-3})$, the computation rounds of ${\mathcal O}(δ^{-1}ε^{-3})$, and the communication rounds of ${\tilde{\mathcal O}}(γ^{-1/2}δ^{-1}ε^{-3})$, where $γ$ is the spectral gap of the mixing matrix for the network. Our results achieve the optimal sample complexity and the sharper communication complexity than existing methods. We also extend our ideas to zeroth-order optimization. Moreover, the numerical experiments show the empirical advantage of our methods.</p></details> |  |
| **[An Adaptive Purification Controller for Quantum Networks: Dynamic Protocol Selection and Multipartite Distillation](https://arxiv.org/abs/2601.18351v2)** | 2026-01-27 | <details><summary>Show</summary><p>Efficient entanglement distribution is the cornerstone of the Quantum Internet. However, physical link parameters such as photon loss, memory coherence time, and gate error rates fluctuate dynamically, rendering static purification strategies suboptimal. In this paper, we propose an Adaptive Purification Controller (APC) that autonomously optimizes the entanglement distillation sequence to maximize the "goodput," the rate of delivered pairs meeting a strict fidelity threshold. By treating protocol selection as a resource allocation problem, the APC dynamically switches between purification depths and protocol families (e.g., BBPSSW vs. DEJMPS) to navigate the trade-off between generation rate and state quality. Using a dynamic programming planner with Pareto pruning, simulation results demonstrate that our approach eliminates the "fidelity cliffs" inherent in static protocols and prevents resource wastage in high-noise regimes. Furthermore, we extend the controller to heterogeneous scenarios, demonstrating robustness for both multipartite GHZ state generation and continuous variable systems using effective noiseless linear amplification models. We benchmark its computational overhead, confirming real-time feasibility with decision latencies in the millisecond range per link.</p></details> |  |
| **[Revisiting Parameter Server in LLM Post-Training](https://arxiv.org/abs/2601.19362v1)** | 2026-01-27 | <details><summary>Show</summary><p>Modern data parallel (DP) training favors collective communication over parameter servers (PS) for its simplicity and efficiency under balanced workloads. However, the balanced workload assumption no longer holds in large language model (LLM) post-training due to the high variance in sequence lengths. Under imbalanced workloads, collective communication creates synchronization barriers, leading to under-utilization of devices with smaller workloads. This change in training dynamics calls for a revisit of the PS paradigm for its robustness to such imbalance. We propose \textbf{On-Demand Communication (ODC)}, which adapts PS into Fully Sharded Data Parallel (FSDP) by replacing collective all-gather and reduce-scatter with direct point-to-point communication. Compared to FSDP, ODC reduces the synchronization barrier from once per layer to once per minibatch and decouples the workload on each device so that faster workers are not stalled. It also enables simpler and more effective load balancing at the minibatch level. Across diverse LLM post-training tasks, ODC consistently improves device utilization and training throughput, achieving up to a 36\% speedup over standard FSDP. These results demonstrate that ODC is a superior fit for the prevalent imbalanced workloads in LLM post-training. Our implementation of ODC and integration with FSDP is open-sourced at https://github.com/sail-sg/odc.</p></details> | Accepted in ICLR'26 |
| **[Peformance Isolation for Inference Processes in Edge GPU Systems](https://arxiv.org/abs/2601.07600v2)** | 2026-01-27 | <details><summary>Show</summary><p>This work analyzes the main isolation mechanisms available in modern NVIDIA GPUs: MPS, MIG, and the recent Green Contexts, to ensure predictable inference time in safety-critical applications using deep learning models. The experimental methodology includes performance tests, evaluation of partitioning impact, and analysis of temporal isolation between processes, considering both the NVIDIA A100 and Jetson Orin platforms. It is observed that MIG provides a high level of isolation. At the same time, Green Contexts represent a promising alternative for edge devices by enabling fine-grained SM allocation with low overhead, albeit without memory isolation. The study also identifies current limitations and outlines potential research directions to improve temporal predictability in shared GPUs.</p></details> |  |
| **[BugLens: Leveraging Bisection for Lightweight Compiler Bug Deduplication](https://arxiv.org/abs/2506.23281v2)** | 2026-01-27 | <details><summary>Show</summary><p>Random testing has proven to be an effective technique for compiler validation. However, the debugging of bugs identified through random testing presents a significant challenge due to the frequent occurrence of duplicate test programs that expose identical compiler bugs. The process to identify duplicates is a practical research problem known as bug deduplication. Prior methodologies for compiler bug deduplication primarily rely on program analysis to extract bug-related features for duplicate identification, which can result in substantial computational overhead and limited generalizability. This paper investigates the feasibility of employing bisection, a standard debugging procedure largely overlooked in prior research on compiler bug deduplication, for this purpose. Our study demonstrates that the utilization of bisection to locate failure-inducing commits provides a valuable criterion for deduplication, albeit one that requires supplementary techniques for more accurate identification. Building on these results, we introduce BugLens, a novel deduplication method that primarily uses bisection, enhanced by the identification of bug-triggering optimizations to minimize false negatives. Empirical evaluations conducted on four real-world datasets demonstrate that BugLens significantly outperforms the state-of-the-art analysis-based methodologies Tamer and D3 by saving an average of 26.98% and 9.64% human effort to identify the same number of distinct bugs. Given the inherent simplicity and generalizability of bisection, it presents a highly practical solution for compiler bug deduplication in real-world applications.</p></details> |  |
| **[Non-Asymptotic Performance Analysis of DOA Estimation Based on Real-Valued Root-MUSIC](https://arxiv.org/abs/2509.01999v3)** | 2026-01-27 | <details><summary>Show</summary><p>This paper presents a systematic theoretical performance analysis of the Real-Valued root-MUSIC (RV-root-MUSIC) algorithm under non-asymptotic conditions. A well-known limitation of RV-root-MUSIC is the estimation ambiguity caused by mirror roots, which are typically suppressed using conventional beamforming (CBF). By leveraging the equivalent subspace constructed through the conjugate extension method and exploiting the equivalence of perturbations for true and mirror roots, this work provides a comprehensive study of three key aspects: noise subspace perturbation, true-root perturbation, and mirror-root perturbation. A statistical model is established, and generalized perturbation expressions are derived. Monte Carlo simulations confirm the correctness and effectiveness of the theoretical results. The analysis provides a rigorous foundation for parameter optimization in Direction-of-Arrival (DOA) estimation, with applications in radar, wireless communications, and intelligent sensing.</p></details> | <details><summary>Accep...</summary><p>Accepted to ICASSP 2026</p></details> |
| **[HybridFlow: Resource-Adaptive Subtask Routing for Efficient Edge-Cloud LLM Inference](https://arxiv.org/abs/2512.22137v3)** | 2026-01-27 | <details><summary>Show</summary><p>Edge-cloud collaborative inference is becoming a practical necessity for LLM-powered edge devices: on-device models often cannot afford the required reasoning capability, while cloud-only inference could be prohibitively costly and slow under strict latency and token/API budgets. However, existing edge-cloud collaboration methods often route per query or fixed steps simply based-on the estimated difficulty. Such coarse and static heuristics overlook subtask dependencies, missing opportunities for parallel execution and budget-adaptive routing. To this end, we propose \textbf{HybridFlow}, a resource-adaptive edge-cloud inference framework that (i) builds a dependency-aware DAG for each query and executes newly unlocked subtasks in parallel, reducing end-to-end latency; (ii) routes each subtask online to the edge or cloud via a learned benefit--cost utility model that dynamically trades accuracy gains against token/API and latency budgets, thereby reducing unnecessary cloud usage while preserving reasoning quality. Across GPQA, MMLU-Pro, AIME24, and LiveBench-Reasoning, HybridFlow improves the cost-accuracy trade-off, reducing latency and cloud API usage while maintaining competitive accuracy against strong structured reasoning baselines.</p></details> |  |

## compiler
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Enabling SSI-Compliant Use of EUDI Wallet Credentials through Trusted Execution Environment and Zero-Knowledge Proof](https://arxiv.org/abs/2601.19893v1)** | 2026-01-27 | <details><summary>Show</summary><p>The passing of the eIDAS amendment marks an important milestone for EU countries and changes how they must manage digital credentials for both public services and businesses. Italy has led in adopting eIDAS, first with CIE and SPID identity schemes, and now with the Italian Wallet (IO app) aligned to eIDAS 2.0. Self-Sovereign Identity (SSI) is a decentralized model born from the success of Distributed Ledgers, giving individuals full control over their digital identity. The current eIDAS 2.0 and its implementation acts diverge from SSI principles, rendering the European Digital Identity Wallet (EUDIW) centralized and merely user-centric, prioritizing security and legal protection over true self-sovereignty. This paper proposes an architecture that enables the use of IT Wallet credentials and services in an SSI-compliant environment through Trusted Execution Environments and Zero-Knowledge Proofs.</p></details> |  |
| **[Self-Sovereign Identity and eIDAS 2.0: An Analysis of Control, Privacy, and Legal Implications](https://arxiv.org/abs/2601.19837v1)** | 2026-01-27 | <details><summary>Show</summary><p>European digital identity initiatives are grounded in regulatory frameworks designed to ensure interoperability and robust, harmonized security standards. The evolution of these frameworks culminates in eIDAS 2.0, whose origins trace back to the Electronic Signatures Directive 1999/93/EC, the first EU-wide legal foundation for the use of electronic signatures in cross-border electronic transactions. As technological capabilities advanced, the initial eIDAS 1.0 framework was increasingly criticized for its limitations and lack of comprehensiveness. Emerging decentralized approaches further exposed these shortcomings and introduced the possibility of integrating innovative identity paradigms, such as Self-Sovereign Identity (SSI) models. In this article, we analyse key provisions of the eIDAS 2.0 Regulation and its accompanying recitals, drawing on existing literature to identify legislative gaps and implementation challenges. Furthermore, we examine the European Digital Identity Architecture and Reference Framework (ARF), assessing its proposed guidelines and evaluating the extent to which its emerging implementations align with SSI principles.</p></details> |  |
| **[Knowledge-Aware Evolution for Streaming Federated Continual Learning with Category Overlap and without Task Identifiers](https://arxiv.org/abs/2601.19788v1)** | 2026-01-27 | <details><summary>Show</summary><p>Federated Continual Learning (FCL) leverages inter-client collaboration to balance new knowledge acquisition and prior knowledge retention in non-stationary data. However, existing batch-based FCL methods lack adaptability to streaming scenarios featuring category overlap between old and new data and absent task identifiers, leading to indistinguishability of old and new knowledge, uncertain task assignments for samples, and knowledge confusion.To address this, we propose streaming federated continual learning setting: per federated learning (FL) round, clients process streaming data with disjoint samples and potentially overlapping categories without task identifiers, necessitating sustained inference capability for all prior categories after each FL round.Next, we introduce FedKACE: 1) an adaptive inference model switching mechanism that enables unidirectional switching from local model to global model to achieve a trade-off between personalization and generalization; 2) a adaptive gradient-balanced replay scheme that reconciles new knowledge learning and old knowledge retention under overlapping-class scenarios; 3) a kernel spectral boundary buffer maintenance that preserves high-information and high-boundary-influence samples to optimize cross-round knowledge retention. Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE.</p></details> |  |
| **[Accelerating radio astronomy imaging with RICK: a step towards SKA-Mid and SKA-Low](https://arxiv.org/abs/2601.19714v1)** | 2026-01-27 | <details><summary>Show</summary><p>The data volumes generated by modern radio interferometers, such as the SKA precursors, present significant computational challenges for imaging pipelines. Addressing the need for high-performance, portable, and scalable software, we present RICK 2.0 (Radio Imaging Code Kernels). This work introduces a novel implementation that leverages the HeFFTe library for distributed Fast Fourier Transforms, ensuring portability across diverse HPC architectures, including multi-core CPUs and accelerators. We validate RICK's correctness and performance against real observational data from both MeerKAT and LOFAR. Our results demonstrate that the HeFFTe-based implementation offers substantial performance advantages, particularly when running on GPUs, and scales effectively with large pixel resolutions and a high number of frequency planes. This new architecture overcomes the critical scaling limitations identified in previous work (Paper II, Paper III), where communication overheads consumed up to 96% of the runtime due to the necessity of communicating the entire grid. This new RICK version drastically reduces this communication impact, representing a scalable and efficient imaging solution ready for the SKA era.</p></details> | <details><summary>29 pa...</summary><p>29 pages, 8 figures, Accepted for publication on Astronomy and Computing Journal</p></details> |
| **[MSCCL++: Rethinking GPU Communication Abstractions for AI Inference](https://arxiv.org/abs/2504.09014v4)** | 2026-01-27 | <details><summary>Show</summary><p>AI applications increasingly run on fast-evolving, heterogeneous hardware to maximize performance, but general-purpose libraries lag in supporting these features. Performance-minded programmers often build custom communication stacks that are fast but error-prone and non-portable. This paper introduces MSCCL++, a design methodology for developing high-performance, portable communication kernels. It provides (1) a low-level, performance-preserving primitive interface that exposes minimal hardware abstractions while hiding the complexities of synchronization and consistency, (2) a higher-level DSL for application developers to implement workload-specific communication algorithms, and (3) a library of efficient algorithms implementing the standard collective API, enabling adoption by users with minimal expertise. Compared to state-of-the-art baselines, MSCCL++ achieves geomean speedups of $1.7\times$ (up to $5.4\times$) for collective communication and $1.2\times$ (up to $1.38\times$) for AI inference workloads. MSCCL++ is in production of multiple AI services provided by Microsoft Azure, and has also been adopted by RCCL, the GPU collective communication library maintained by AMD. MSCCL++ is open source and available at https://github.com/microsoft/mscclpp . Our two years of experience with MSCCL++ suggests that its abstractions are robust, enabling support for new hardware features, such as multimem, within weeks of development.</p></details> | 15 pages, 13 figures |
| **[Parallel Spawning Strategies for Dynamic-Aware MPI Applications](https://arxiv.org/abs/2511.04268v2)** | 2026-01-27 | <details><summary>Show</summary><p>Dynamic resource management is an increasingly important capability of High Performance Computing systems, as it enables jobs to adjust their resource allocation at runtime. This capability can reduce workload makespan, substantially decreasing job waiting times and optimizing resource allocation. In this context, malleability refers to the ability of applications to adapt to new resource allocations during execution. Although beneficial, malleability incurs significant reconfiguration costs, making the reduction of these costs an important research topic. Some existing solutions for MPI applications respawn the entire application, which is an expensive solution that avoids the reuse of original processes. Other MPI solutions reuse them, but fail to fully release unneeded processes when shrinking, since some ranks within the same communicator remain active across nodes, preventing the application from returning those nodes to the system. This work overcomes both limitations by proposing a novel parallel spawning strategy, in which all processes cooperate in the spawning. This allows expansions to reuse processes while also terminating unneeded ones. This strategy has been validated on two systems with either machines with equal or different numbers of cores. Experiments show that this strategy preserves competitive expansion times with at most a $1.13\times$ and $1.25\times$ overhead for equal and different number of cores per node, respectively. More importantly, it enables fast shrink operations that reduce their cost by at least $1387\times$ and $20\times$ in the same scenarios.</p></details> | <details><summary>14 pa...</summary><p>14 pages, 2 Tables, 6 Figures, 9 Equations, 4 Listings</p></details> |
| **[Minimmit: Fast Finality with Even Faster Blocks](https://arxiv.org/abs/2508.10862v7)** | 2026-01-27 | <details><summary>Show</summary><p>Achieving low-latency consensus in geographically distributed systems remains a key challenge for blockchain and distributed database applications. To this end, there has been significant recent interest in State-Machine-Replication (SMR) protocols that achieve 2-round finality under the assumption that $5f+1\leq n$, where $n$ is the number of processors and $f$ bounds the number of processors that may exhibit Byzantine faults. In these protocols, instructions are organised into views, each led by a different designated leader, and 2-round finality means that a leader's proposal can be finalised after just a single round of voting, meaning two rounds overall (one round for the proposal and one for voting). We introduce Minimmit, a Byzantine-fault-tolerant SMR protocol with lower latency than previous 2-round finality approaches. Our key insight is that view progression and transaction finality can operate on different quorum thresholds without compromising safety or liveness. Experiments simulating a globally distributed network of 50 processors, uniformly assigned across ten virtual regions, show that the approach leads to a 23.1% reduction in view latency and a 10.7% reduction in transaction latency compared to the state-of-the-art.</p></details> |  |
| **[Convex Hull 3D Filtering with GPU Ray Tracing and Tensor Cores](https://arxiv.org/abs/2601.19647v1)** | 2026-01-27 | <details><summary>Show</summary><p>In recent years, applications such as real-time simulations, autonomous systems, and video games increasingly demand the processing of complex geometric models under stringent time constraints. Traditional geometric algorithms, including the convex hull, are subject to these challenges. A common approach to improve performance is scaling computational resources, which often results in higher energy consumption. Given the growing global concern regarding sustainable use of energy, this becomes a critical limitation. This work presents a 3D preprocessing filter for the convex hull algorithm using ray tracing and tensor core technologies. The filter builds a delimiter polyhedron based on Manhattan distances that discards points from the original set. The filter is evaluated on two point distributions: uniform and sphere. Experimental results show that the proposed filter, combined with convex hull construction, accelerates the computation of the 3D convex hull by up to $200 \times$ with respect to a CPU parallel implementation. This research demonstrates that geometric algorithms can be accelerated through massive parallelism while maintaining efficient energy utilization. Beyond execution time and speedup evaluation, we also analyze GPU energy consumption, showing that the proposed preprocessing filter not only reduces the computational workload but also achieves performance gains with controlled energy usage. These results highlight the dual benefit of the method in terms of both speed and energy efficiency, reinforcing its applicability in modern high-performance scenarios.</p></details> |  |
| **[Modular Foundation Model Inference at the Edge: Network-Aware Microservice Optimization](https://arxiv.org/abs/2601.19563v1)** | 2026-01-27 | <details><summary>Show</summary><p>Foundation models (FMs) unlock unprecedented multimodal and multitask intelligence, yet their cloud-centric deployment precludes real-time responsiveness and compromises user privacy. Meanwhile, monolithic execution at the edge remains infeasible under stringent resource limits and uncertain network dynamics. To bridge this gap, we propose a microservice-based FM inference framework that exploits the intrinsic functional asymmetry between heavyweight core services and agile light services. Our two-tier deployment strategy ensures robust Quality of Service (QoS) under resource contention. Specifically, core services are placed statically via a long-term network-aware integer program with sparsity constraints to form a fault-tolerant backbone. On the other hand, light services are orchestrated dynamically by a low-complexity online controller that integrates effective capacity theory with Lyapunov optimization, providing probabilistic latency guarantees under real-time workload fluctuations. Simulations demonstrate that our framework achieves over 84% average on-time task completion with moderate deployment costs and maintains strong robustness as the system load scales.</p></details> | <details><summary>4 fig...</summary><p>4 figures. Conference</p></details> |
| **[Rule-Based Graph Programs Matching the Time Complexity of Imperative Algorithms](https://arxiv.org/abs/2501.09144v4)** | 2026-01-27 | <details><summary>Show</summary><p>We report on recent advances in rule-based graph programming, which allow us to match the time complexity of some fundamental imperative graph algorithms. In general, achieving the time complexity of graph algorithms implemented in conventional languages using a rule-based graph-transformation language is challenging due to the cost of graph matching. Previous work demonstrated that with rooted rules, certain algorithms can be implemented in the graph programming language GP 2 such that their runtime matches the time complexity of imperative implementations. However, this required input graphs to have a bounded node degree and (for some algorithms) to be connected. In this paper, we overcome these limitations by enhancing the graph data structure generated by the GP 2 compiler and exploiting the new structure in programs. We present three case studies: the first program checks whether input graphs are connected, the second program checks whether input graphs are acyclic, and the third program solves the single-source shortest-paths problem for graphs with integer edge-weights. The first two programs run in linear time on (possibly disconnected) input graphs with arbitrary node degrees. The third program runs in time $O(nm)$ on arbitrary input graphs, matching the time complexity of imperative implementations of the Bellman-Ford algorithm. For each program, we formally prove its correctness and time complexity, and provide runtime experiments on various graph classes.</p></details> | LMCS |
| **[Optimizing FaaS Platforms for MCP-enabled Agentic Workflows](https://arxiv.org/abs/2601.14735v2)** | 2026-01-27 | <details><summary>Show</summary><p>Agentic workflows that use autonomous AI Agents powered by Large Language Models (LLMs) and Model Context Protocol (MCP) servers is rapidly rising. This introduces challenges in scalable cloud deployment and state management. Traditional hosting on Virtual Machines (VMs) is resource-intensive and lacks elasticity. Functions-as-a-Service (FaaS) platforms offer modularity, autoscaling and cost efficiency but are inherently stateless. In this paper, we present the FAME, a FaaS-based architecture for orchestrating MCP-enabled agentic workflows. FAME decomposes agentic patterns such as ReAct into composable agents: Planner, Actor and Evaluator, that are each a FaaS function built using LangGraph and are orchestrated as a FaaS workflow. This enables modular composition as AWS Step Functions and avoids function timeouts seen for monolithic agentic workflows. To address context persistence across user requests in a conversation, FAME automates agent memory persistence and injection using DynamoDB. It also optimizes MCP server deployment through AWS Lambda wrappers, caches tool outputs in S3 and proposes function fusion strategies. We evaluate FAME on two representative applications, on research paper summarization and log analytics, under diverse memory and caching configurations. Results show up to 13x latency reduction, 88% fewer input tokens and 66% in cost savings, along with improved workflow completion rates. This demonstrates the viability of serverless platforms for hosting complex, multi-agent AI workflows at scale.</p></details> |  |
| **[For Generalised Algebraic Theories, Two Sorts Are Enough](https://arxiv.org/abs/2601.19426v1)** | 2026-01-27 | <details><summary>Show</summary><p>Generalised algebraic theories (GATs) allow multiple sorts indexed over each other. For example, the theories of categories or Martin-L{ö}f type theories form GATs. Categories have two sorts, objects and morphisms, and the latter are double-indexed over the former. Martin-L{ö}f type theory has four sorts: contexts, substitutions, types and terms. For example, types are indexed over contexts, and terms are indexed over both contexts and types. In this paper we show that any GAT can be reduced to a GAT with only two sorts, and there is a section-retraction correspondence (formally, a strict coreflection) between models of the original and the reduced GAT. In particular, any model of the original GAT can be turned into a model of the reduced (two-sorted) GAT and back, and this roundtrip is the identity. The reduced GAT is simpler than the original GAT in the following aspects: it does not have sort equalities; it does not have interleaved sorts and operations; if the original GAT did not have interleaved sorts and operations, then the reduced GAT won't have operations interleaved between different sorts. In a type-theoretic metatheory, the initial algebra of a GAT is called a quotient inductive-inductive type (QIIT). Our reduction provides a way to implement QIITs with sort equalities or interleaved constructors which are not allowed by Cubical Agda. An instance of our reduction is the well-known method of reducing mutual inductive types to a single indexed family. Our approach is semantic in that it does not rely on a syntactic description of GATs, but instead, on Uemura's bi-initial characterisation of the category of (finite) GATs in the 2-category of finitely complete categories with a chosen exponentiable morphism.</p></details> |  |
| **[Specifying and Verifying RDMA Synchronisation (Extended Version)](https://arxiv.org/abs/2601.14642v2)** | 2026-01-27 | <details><summary>Show</summary><p>Remote direct memory access (RDMA) allows a machine to directly read from and write to the memory of remote machine, enabling high-throughput, low-latency data transfer. Ensuring correctness of RDMA programs has only recently become possible with the formalisation of $\text{RDMA}^\text{TSO}$ semantics (describing the behaviour of RDMA networking over a TSO CPU). However, this semantics currently lacks a formalisation of remote synchronisation, meaning that the implementations of common abstractions such as locks cannot be verified. In this paper, we close this gap by presenting $\text{RDMA}^{\text{TSO}}_{\text{RMW}}$, the first semantics for remote `read-modify-write' (RMW) instructions over TSO. It turns out that remote RMW operations are weak and only ensure atomicity against other remote RMWs. We therefore build a set of composable synchronisation abstractions starting with the $\text{RDMA}^{\text{WAIT}}_{\text{RMW}}$ library. Underpinned by $\text{RDMA}^{\text{WAIT}}_{\text{RMW}}$, we then specify, implement and verify three classes of remote locks that are suitable for different scenarios. Additionally, we develop the notion of a strong RDMA model, $\text{RDMA}^{\text{SC}}_{\text{RMW}}$, which is akin to sequential consistency in shared memory architectures. Our libraries are built to be compatible with an existing set of high-performance libraries called LOCO, which ensures compositionality and verifiability.</p></details> | <details><summary>95 pa...</summary><p>95 pages, extended version of ESOP 2026 paper, replaced to fix a tikz opacity problem</p></details> |
| **[Decentralized Nonsmooth Nonconvex Optimization with Client Sampling](https://arxiv.org/abs/2601.19381v1)** | 2026-01-27 | <details><summary>Show</summary><p>This paper considers decentralized nonsmooth nonconvex optimization problem with Lipschitz continuous local functions. We propose an efficient stochastic first-order method with client sampling, achieving the $(δ,ε)$-Goldstein stationary point with the overall sample complexity of ${\mathcal O}(δ^{-1}ε^{-3})$, the computation rounds of ${\mathcal O}(δ^{-1}ε^{-3})$, and the communication rounds of ${\tilde{\mathcal O}}(γ^{-1/2}δ^{-1}ε^{-3})$, where $γ$ is the spectral gap of the mixing matrix for the network. Our results achieve the optimal sample complexity and the sharper communication complexity than existing methods. We also extend our ideas to zeroth-order optimization. Moreover, the numerical experiments show the empirical advantage of our methods.</p></details> |  |
| **[An Adaptive Purification Controller for Quantum Networks: Dynamic Protocol Selection and Multipartite Distillation](https://arxiv.org/abs/2601.18351v2)** | 2026-01-27 | <details><summary>Show</summary><p>Efficient entanglement distribution is the cornerstone of the Quantum Internet. However, physical link parameters such as photon loss, memory coherence time, and gate error rates fluctuate dynamically, rendering static purification strategies suboptimal. In this paper, we propose an Adaptive Purification Controller (APC) that autonomously optimizes the entanglement distillation sequence to maximize the "goodput," the rate of delivered pairs meeting a strict fidelity threshold. By treating protocol selection as a resource allocation problem, the APC dynamically switches between purification depths and protocol families (e.g., BBPSSW vs. DEJMPS) to navigate the trade-off between generation rate and state quality. Using a dynamic programming planner with Pareto pruning, simulation results demonstrate that our approach eliminates the "fidelity cliffs" inherent in static protocols and prevents resource wastage in high-noise regimes. Furthermore, we extend the controller to heterogeneous scenarios, demonstrating robustness for both multipartite GHZ state generation and continuous variable systems using effective noiseless linear amplification models. We benchmark its computational overhead, confirming real-time feasibility with decision latencies in the millisecond range per link.</p></details> |  |
| **[Revisiting Parameter Server in LLM Post-Training](https://arxiv.org/abs/2601.19362v1)** | 2026-01-27 | <details><summary>Show</summary><p>Modern data parallel (DP) training favors collective communication over parameter servers (PS) for its simplicity and efficiency under balanced workloads. However, the balanced workload assumption no longer holds in large language model (LLM) post-training due to the high variance in sequence lengths. Under imbalanced workloads, collective communication creates synchronization barriers, leading to under-utilization of devices with smaller workloads. This change in training dynamics calls for a revisit of the PS paradigm for its robustness to such imbalance. We propose \textbf{On-Demand Communication (ODC)}, which adapts PS into Fully Sharded Data Parallel (FSDP) by replacing collective all-gather and reduce-scatter with direct point-to-point communication. Compared to FSDP, ODC reduces the synchronization barrier from once per layer to once per minibatch and decouples the workload on each device so that faster workers are not stalled. It also enables simpler and more effective load balancing at the minibatch level. Across diverse LLM post-training tasks, ODC consistently improves device utilization and training throughput, achieving up to a 36\% speedup over standard FSDP. These results demonstrate that ODC is a superior fit for the prevalent imbalanced workloads in LLM post-training. Our implementation of ODC and integration with FSDP is open-sourced at https://github.com/sail-sg/odc.</p></details> | Accepted in ICLR'26 |
| **[Peformance Isolation for Inference Processes in Edge GPU Systems](https://arxiv.org/abs/2601.07600v2)** | 2026-01-27 | <details><summary>Show</summary><p>This work analyzes the main isolation mechanisms available in modern NVIDIA GPUs: MPS, MIG, and the recent Green Contexts, to ensure predictable inference time in safety-critical applications using deep learning models. The experimental methodology includes performance tests, evaluation of partitioning impact, and analysis of temporal isolation between processes, considering both the NVIDIA A100 and Jetson Orin platforms. It is observed that MIG provides a high level of isolation. At the same time, Green Contexts represent a promising alternative for edge devices by enabling fine-grained SM allocation with low overhead, albeit without memory isolation. The study also identifies current limitations and outlines potential research directions to improve temporal predictability in shared GPUs.</p></details> |  |
| **[BugLens: Leveraging Bisection for Lightweight Compiler Bug Deduplication](https://arxiv.org/abs/2506.23281v2)** | 2026-01-27 | <details><summary>Show</summary><p>Random testing has proven to be an effective technique for compiler validation. However, the debugging of bugs identified through random testing presents a significant challenge due to the frequent occurrence of duplicate test programs that expose identical compiler bugs. The process to identify duplicates is a practical research problem known as bug deduplication. Prior methodologies for compiler bug deduplication primarily rely on program analysis to extract bug-related features for duplicate identification, which can result in substantial computational overhead and limited generalizability. This paper investigates the feasibility of employing bisection, a standard debugging procedure largely overlooked in prior research on compiler bug deduplication, for this purpose. Our study demonstrates that the utilization of bisection to locate failure-inducing commits provides a valuable criterion for deduplication, albeit one that requires supplementary techniques for more accurate identification. Building on these results, we introduce BugLens, a novel deduplication method that primarily uses bisection, enhanced by the identification of bug-triggering optimizations to minimize false negatives. Empirical evaluations conducted on four real-world datasets demonstrate that BugLens significantly outperforms the state-of-the-art analysis-based methodologies Tamer and D3 by saving an average of 26.98% and 9.64% human effort to identify the same number of distinct bugs. Given the inherent simplicity and generalizability of bisection, it presents a highly practical solution for compiler bug deduplication in real-world applications.</p></details> |  |
| **[Non-Asymptotic Performance Analysis of DOA Estimation Based on Real-Valued Root-MUSIC](https://arxiv.org/abs/2509.01999v3)** | 2026-01-27 | <details><summary>Show</summary><p>This paper presents a systematic theoretical performance analysis of the Real-Valued root-MUSIC (RV-root-MUSIC) algorithm under non-asymptotic conditions. A well-known limitation of RV-root-MUSIC is the estimation ambiguity caused by mirror roots, which are typically suppressed using conventional beamforming (CBF). By leveraging the equivalent subspace constructed through the conjugate extension method and exploiting the equivalence of perturbations for true and mirror roots, this work provides a comprehensive study of three key aspects: noise subspace perturbation, true-root perturbation, and mirror-root perturbation. A statistical model is established, and generalized perturbation expressions are derived. Monte Carlo simulations confirm the correctness and effectiveness of the theoretical results. The analysis provides a rigorous foundation for parameter optimization in Direction-of-Arrival (DOA) estimation, with applications in radar, wireless communications, and intelligent sensing.</p></details> | <details><summary>Accep...</summary><p>Accepted to ICASSP 2026</p></details> |
| **[HybridFlow: Resource-Adaptive Subtask Routing for Efficient Edge-Cloud LLM Inference](https://arxiv.org/abs/2512.22137v3)** | 2026-01-27 | <details><summary>Show</summary><p>Edge-cloud collaborative inference is becoming a practical necessity for LLM-powered edge devices: on-device models often cannot afford the required reasoning capability, while cloud-only inference could be prohibitively costly and slow under strict latency and token/API budgets. However, existing edge-cloud collaboration methods often route per query or fixed steps simply based-on the estimated difficulty. Such coarse and static heuristics overlook subtask dependencies, missing opportunities for parallel execution and budget-adaptive routing. To this end, we propose \textbf{HybridFlow}, a resource-adaptive edge-cloud inference framework that (i) builds a dependency-aware DAG for each query and executes newly unlocked subtasks in parallel, reducing end-to-end latency; (ii) routes each subtask online to the edge or cloud via a learned benefit--cost utility model that dynamically trades accuracy gains against token/API and latency budgets, thereby reducing unnecessary cloud usage while preserving reasoning quality. Across GPQA, MMLU-Pro, AIME24, and LiveBench-Reasoning, HybridFlow improves the cost-accuracy trade-off, reducing latency and cloud API usage while maintaining competitive accuracy against strong structured reasoning baselines.</p></details> |  |

## performance
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Enabling SSI-Compliant Use of EUDI Wallet Credentials through Trusted Execution Environment and Zero-Knowledge Proof](https://arxiv.org/abs/2601.19893v1)** | 2026-01-27 | <details><summary>Show</summary><p>The passing of the eIDAS amendment marks an important milestone for EU countries and changes how they must manage digital credentials for both public services and businesses. Italy has led in adopting eIDAS, first with CIE and SPID identity schemes, and now with the Italian Wallet (IO app) aligned to eIDAS 2.0. Self-Sovereign Identity (SSI) is a decentralized model born from the success of Distributed Ledgers, giving individuals full control over their digital identity. The current eIDAS 2.0 and its implementation acts diverge from SSI principles, rendering the European Digital Identity Wallet (EUDIW) centralized and merely user-centric, prioritizing security and legal protection over true self-sovereignty. This paper proposes an architecture that enables the use of IT Wallet credentials and services in an SSI-compliant environment through Trusted Execution Environments and Zero-Knowledge Proofs.</p></details> |  |
| **[Self-Sovereign Identity and eIDAS 2.0: An Analysis of Control, Privacy, and Legal Implications](https://arxiv.org/abs/2601.19837v1)** | 2026-01-27 | <details><summary>Show</summary><p>European digital identity initiatives are grounded in regulatory frameworks designed to ensure interoperability and robust, harmonized security standards. The evolution of these frameworks culminates in eIDAS 2.0, whose origins trace back to the Electronic Signatures Directive 1999/93/EC, the first EU-wide legal foundation for the use of electronic signatures in cross-border electronic transactions. As technological capabilities advanced, the initial eIDAS 1.0 framework was increasingly criticized for its limitations and lack of comprehensiveness. Emerging decentralized approaches further exposed these shortcomings and introduced the possibility of integrating innovative identity paradigms, such as Self-Sovereign Identity (SSI) models. In this article, we analyse key provisions of the eIDAS 2.0 Regulation and its accompanying recitals, drawing on existing literature to identify legislative gaps and implementation challenges. Furthermore, we examine the European Digital Identity Architecture and Reference Framework (ARF), assessing its proposed guidelines and evaluating the extent to which its emerging implementations align with SSI principles.</p></details> |  |
| **[Knowledge-Aware Evolution for Streaming Federated Continual Learning with Category Overlap and without Task Identifiers](https://arxiv.org/abs/2601.19788v1)** | 2026-01-27 | <details><summary>Show</summary><p>Federated Continual Learning (FCL) leverages inter-client collaboration to balance new knowledge acquisition and prior knowledge retention in non-stationary data. However, existing batch-based FCL methods lack adaptability to streaming scenarios featuring category overlap between old and new data and absent task identifiers, leading to indistinguishability of old and new knowledge, uncertain task assignments for samples, and knowledge confusion.To address this, we propose streaming federated continual learning setting: per federated learning (FL) round, clients process streaming data with disjoint samples and potentially overlapping categories without task identifiers, necessitating sustained inference capability for all prior categories after each FL round.Next, we introduce FedKACE: 1) an adaptive inference model switching mechanism that enables unidirectional switching from local model to global model to achieve a trade-off between personalization and generalization; 2) a adaptive gradient-balanced replay scheme that reconciles new knowledge learning and old knowledge retention under overlapping-class scenarios; 3) a kernel spectral boundary buffer maintenance that preserves high-information and high-boundary-influence samples to optimize cross-round knowledge retention. Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE.</p></details> |  |
| **[Accelerating radio astronomy imaging with RICK: a step towards SKA-Mid and SKA-Low](https://arxiv.org/abs/2601.19714v1)** | 2026-01-27 | <details><summary>Show</summary><p>The data volumes generated by modern radio interferometers, such as the SKA precursors, present significant computational challenges for imaging pipelines. Addressing the need for high-performance, portable, and scalable software, we present RICK 2.0 (Radio Imaging Code Kernels). This work introduces a novel implementation that leverages the HeFFTe library for distributed Fast Fourier Transforms, ensuring portability across diverse HPC architectures, including multi-core CPUs and accelerators. We validate RICK's correctness and performance against real observational data from both MeerKAT and LOFAR. Our results demonstrate that the HeFFTe-based implementation offers substantial performance advantages, particularly when running on GPUs, and scales effectively with large pixel resolutions and a high number of frequency planes. This new architecture overcomes the critical scaling limitations identified in previous work (Paper II, Paper III), where communication overheads consumed up to 96% of the runtime due to the necessity of communicating the entire grid. This new RICK version drastically reduces this communication impact, representing a scalable and efficient imaging solution ready for the SKA era.</p></details> | <details><summary>29 pa...</summary><p>29 pages, 8 figures, Accepted for publication on Astronomy and Computing Journal</p></details> |
| **[MSCCL++: Rethinking GPU Communication Abstractions for AI Inference](https://arxiv.org/abs/2504.09014v4)** | 2026-01-27 | <details><summary>Show</summary><p>AI applications increasingly run on fast-evolving, heterogeneous hardware to maximize performance, but general-purpose libraries lag in supporting these features. Performance-minded programmers often build custom communication stacks that are fast but error-prone and non-portable. This paper introduces MSCCL++, a design methodology for developing high-performance, portable communication kernels. It provides (1) a low-level, performance-preserving primitive interface that exposes minimal hardware abstractions while hiding the complexities of synchronization and consistency, (2) a higher-level DSL for application developers to implement workload-specific communication algorithms, and (3) a library of efficient algorithms implementing the standard collective API, enabling adoption by users with minimal expertise. Compared to state-of-the-art baselines, MSCCL++ achieves geomean speedups of $1.7\times$ (up to $5.4\times$) for collective communication and $1.2\times$ (up to $1.38\times$) for AI inference workloads. MSCCL++ is in production of multiple AI services provided by Microsoft Azure, and has also been adopted by RCCL, the GPU collective communication library maintained by AMD. MSCCL++ is open source and available at https://github.com/microsoft/mscclpp . Our two years of experience with MSCCL++ suggests that its abstractions are robust, enabling support for new hardware features, such as multimem, within weeks of development.</p></details> | 15 pages, 13 figures |
| **[Parallel Spawning Strategies for Dynamic-Aware MPI Applications](https://arxiv.org/abs/2511.04268v2)** | 2026-01-27 | <details><summary>Show</summary><p>Dynamic resource management is an increasingly important capability of High Performance Computing systems, as it enables jobs to adjust their resource allocation at runtime. This capability can reduce workload makespan, substantially decreasing job waiting times and optimizing resource allocation. In this context, malleability refers to the ability of applications to adapt to new resource allocations during execution. Although beneficial, malleability incurs significant reconfiguration costs, making the reduction of these costs an important research topic. Some existing solutions for MPI applications respawn the entire application, which is an expensive solution that avoids the reuse of original processes. Other MPI solutions reuse them, but fail to fully release unneeded processes when shrinking, since some ranks within the same communicator remain active across nodes, preventing the application from returning those nodes to the system. This work overcomes both limitations by proposing a novel parallel spawning strategy, in which all processes cooperate in the spawning. This allows expansions to reuse processes while also terminating unneeded ones. This strategy has been validated on two systems with either machines with equal or different numbers of cores. Experiments show that this strategy preserves competitive expansion times with at most a $1.13\times$ and $1.25\times$ overhead for equal and different number of cores per node, respectively. More importantly, it enables fast shrink operations that reduce their cost by at least $1387\times$ and $20\times$ in the same scenarios.</p></details> | <details><summary>14 pa...</summary><p>14 pages, 2 Tables, 6 Figures, 9 Equations, 4 Listings</p></details> |
| **[Minimmit: Fast Finality with Even Faster Blocks](https://arxiv.org/abs/2508.10862v7)** | 2026-01-27 | <details><summary>Show</summary><p>Achieving low-latency consensus in geographically distributed systems remains a key challenge for blockchain and distributed database applications. To this end, there has been significant recent interest in State-Machine-Replication (SMR) protocols that achieve 2-round finality under the assumption that $5f+1\leq n$, where $n$ is the number of processors and $f$ bounds the number of processors that may exhibit Byzantine faults. In these protocols, instructions are organised into views, each led by a different designated leader, and 2-round finality means that a leader's proposal can be finalised after just a single round of voting, meaning two rounds overall (one round for the proposal and one for voting). We introduce Minimmit, a Byzantine-fault-tolerant SMR protocol with lower latency than previous 2-round finality approaches. Our key insight is that view progression and transaction finality can operate on different quorum thresholds without compromising safety or liveness. Experiments simulating a globally distributed network of 50 processors, uniformly assigned across ten virtual regions, show that the approach leads to a 23.1% reduction in view latency and a 10.7% reduction in transaction latency compared to the state-of-the-art.</p></details> |  |
| **[Convex Hull 3D Filtering with GPU Ray Tracing and Tensor Cores](https://arxiv.org/abs/2601.19647v1)** | 2026-01-27 | <details><summary>Show</summary><p>In recent years, applications such as real-time simulations, autonomous systems, and video games increasingly demand the processing of complex geometric models under stringent time constraints. Traditional geometric algorithms, including the convex hull, are subject to these challenges. A common approach to improve performance is scaling computational resources, which often results in higher energy consumption. Given the growing global concern regarding sustainable use of energy, this becomes a critical limitation. This work presents a 3D preprocessing filter for the convex hull algorithm using ray tracing and tensor core technologies. The filter builds a delimiter polyhedron based on Manhattan distances that discards points from the original set. The filter is evaluated on two point distributions: uniform and sphere. Experimental results show that the proposed filter, combined with convex hull construction, accelerates the computation of the 3D convex hull by up to $200 \times$ with respect to a CPU parallel implementation. This research demonstrates that geometric algorithms can be accelerated through massive parallelism while maintaining efficient energy utilization. Beyond execution time and speedup evaluation, we also analyze GPU energy consumption, showing that the proposed preprocessing filter not only reduces the computational workload but also achieves performance gains with controlled energy usage. These results highlight the dual benefit of the method in terms of both speed and energy efficiency, reinforcing its applicability in modern high-performance scenarios.</p></details> |  |
| **[Modular Foundation Model Inference at the Edge: Network-Aware Microservice Optimization](https://arxiv.org/abs/2601.19563v1)** | 2026-01-27 | <details><summary>Show</summary><p>Foundation models (FMs) unlock unprecedented multimodal and multitask intelligence, yet their cloud-centric deployment precludes real-time responsiveness and compromises user privacy. Meanwhile, monolithic execution at the edge remains infeasible under stringent resource limits and uncertain network dynamics. To bridge this gap, we propose a microservice-based FM inference framework that exploits the intrinsic functional asymmetry between heavyweight core services and agile light services. Our two-tier deployment strategy ensures robust Quality of Service (QoS) under resource contention. Specifically, core services are placed statically via a long-term network-aware integer program with sparsity constraints to form a fault-tolerant backbone. On the other hand, light services are orchestrated dynamically by a low-complexity online controller that integrates effective capacity theory with Lyapunov optimization, providing probabilistic latency guarantees under real-time workload fluctuations. Simulations demonstrate that our framework achieves over 84% average on-time task completion with moderate deployment costs and maintains strong robustness as the system load scales.</p></details> | <details><summary>4 fig...</summary><p>4 figures. Conference</p></details> |
| **[Rule-Based Graph Programs Matching the Time Complexity of Imperative Algorithms](https://arxiv.org/abs/2501.09144v4)** | 2026-01-27 | <details><summary>Show</summary><p>We report on recent advances in rule-based graph programming, which allow us to match the time complexity of some fundamental imperative graph algorithms. In general, achieving the time complexity of graph algorithms implemented in conventional languages using a rule-based graph-transformation language is challenging due to the cost of graph matching. Previous work demonstrated that with rooted rules, certain algorithms can be implemented in the graph programming language GP 2 such that their runtime matches the time complexity of imperative implementations. However, this required input graphs to have a bounded node degree and (for some algorithms) to be connected. In this paper, we overcome these limitations by enhancing the graph data structure generated by the GP 2 compiler and exploiting the new structure in programs. We present three case studies: the first program checks whether input graphs are connected, the second program checks whether input graphs are acyclic, and the third program solves the single-source shortest-paths problem for graphs with integer edge-weights. The first two programs run in linear time on (possibly disconnected) input graphs with arbitrary node degrees. The third program runs in time $O(nm)$ on arbitrary input graphs, matching the time complexity of imperative implementations of the Bellman-Ford algorithm. For each program, we formally prove its correctness and time complexity, and provide runtime experiments on various graph classes.</p></details> | LMCS |
| **[Optimizing FaaS Platforms for MCP-enabled Agentic Workflows](https://arxiv.org/abs/2601.14735v2)** | 2026-01-27 | <details><summary>Show</summary><p>Agentic workflows that use autonomous AI Agents powered by Large Language Models (LLMs) and Model Context Protocol (MCP) servers is rapidly rising. This introduces challenges in scalable cloud deployment and state management. Traditional hosting on Virtual Machines (VMs) is resource-intensive and lacks elasticity. Functions-as-a-Service (FaaS) platforms offer modularity, autoscaling and cost efficiency but are inherently stateless. In this paper, we present the FAME, a FaaS-based architecture for orchestrating MCP-enabled agentic workflows. FAME decomposes agentic patterns such as ReAct into composable agents: Planner, Actor and Evaluator, that are each a FaaS function built using LangGraph and are orchestrated as a FaaS workflow. This enables modular composition as AWS Step Functions and avoids function timeouts seen for monolithic agentic workflows. To address context persistence across user requests in a conversation, FAME automates agent memory persistence and injection using DynamoDB. It also optimizes MCP server deployment through AWS Lambda wrappers, caches tool outputs in S3 and proposes function fusion strategies. We evaluate FAME on two representative applications, on research paper summarization and log analytics, under diverse memory and caching configurations. Results show up to 13x latency reduction, 88% fewer input tokens and 66% in cost savings, along with improved workflow completion rates. This demonstrates the viability of serverless platforms for hosting complex, multi-agent AI workflows at scale.</p></details> |  |
| **[For Generalised Algebraic Theories, Two Sorts Are Enough](https://arxiv.org/abs/2601.19426v1)** | 2026-01-27 | <details><summary>Show</summary><p>Generalised algebraic theories (GATs) allow multiple sorts indexed over each other. For example, the theories of categories or Martin-L{ö}f type theories form GATs. Categories have two sorts, objects and morphisms, and the latter are double-indexed over the former. Martin-L{ö}f type theory has four sorts: contexts, substitutions, types and terms. For example, types are indexed over contexts, and terms are indexed over both contexts and types. In this paper we show that any GAT can be reduced to a GAT with only two sorts, and there is a section-retraction correspondence (formally, a strict coreflection) between models of the original and the reduced GAT. In particular, any model of the original GAT can be turned into a model of the reduced (two-sorted) GAT and back, and this roundtrip is the identity. The reduced GAT is simpler than the original GAT in the following aspects: it does not have sort equalities; it does not have interleaved sorts and operations; if the original GAT did not have interleaved sorts and operations, then the reduced GAT won't have operations interleaved between different sorts. In a type-theoretic metatheory, the initial algebra of a GAT is called a quotient inductive-inductive type (QIIT). Our reduction provides a way to implement QIITs with sort equalities or interleaved constructors which are not allowed by Cubical Agda. An instance of our reduction is the well-known method of reducing mutual inductive types to a single indexed family. Our approach is semantic in that it does not rely on a syntactic description of GATs, but instead, on Uemura's bi-initial characterisation of the category of (finite) GATs in the 2-category of finitely complete categories with a chosen exponentiable morphism.</p></details> |  |
| **[Specifying and Verifying RDMA Synchronisation (Extended Version)](https://arxiv.org/abs/2601.14642v2)** | 2026-01-27 | <details><summary>Show</summary><p>Remote direct memory access (RDMA) allows a machine to directly read from and write to the memory of remote machine, enabling high-throughput, low-latency data transfer. Ensuring correctness of RDMA programs has only recently become possible with the formalisation of $\text{RDMA}^\text{TSO}$ semantics (describing the behaviour of RDMA networking over a TSO CPU). However, this semantics currently lacks a formalisation of remote synchronisation, meaning that the implementations of common abstractions such as locks cannot be verified. In this paper, we close this gap by presenting $\text{RDMA}^{\text{TSO}}_{\text{RMW}}$, the first semantics for remote `read-modify-write' (RMW) instructions over TSO. It turns out that remote RMW operations are weak and only ensure atomicity against other remote RMWs. We therefore build a set of composable synchronisation abstractions starting with the $\text{RDMA}^{\text{WAIT}}_{\text{RMW}}$ library. Underpinned by $\text{RDMA}^{\text{WAIT}}_{\text{RMW}}$, we then specify, implement and verify three classes of remote locks that are suitable for different scenarios. Additionally, we develop the notion of a strong RDMA model, $\text{RDMA}^{\text{SC}}_{\text{RMW}}$, which is akin to sequential consistency in shared memory architectures. Our libraries are built to be compatible with an existing set of high-performance libraries called LOCO, which ensures compositionality and verifiability.</p></details> | <details><summary>95 pa...</summary><p>95 pages, extended version of ESOP 2026 paper, replaced to fix a tikz opacity problem</p></details> |
| **[Decentralized Nonsmooth Nonconvex Optimization with Client Sampling](https://arxiv.org/abs/2601.19381v1)** | 2026-01-27 | <details><summary>Show</summary><p>This paper considers decentralized nonsmooth nonconvex optimization problem with Lipschitz continuous local functions. We propose an efficient stochastic first-order method with client sampling, achieving the $(δ,ε)$-Goldstein stationary point with the overall sample complexity of ${\mathcal O}(δ^{-1}ε^{-3})$, the computation rounds of ${\mathcal O}(δ^{-1}ε^{-3})$, and the communication rounds of ${\tilde{\mathcal O}}(γ^{-1/2}δ^{-1}ε^{-3})$, where $γ$ is the spectral gap of the mixing matrix for the network. Our results achieve the optimal sample complexity and the sharper communication complexity than existing methods. We also extend our ideas to zeroth-order optimization. Moreover, the numerical experiments show the empirical advantage of our methods.</p></details> |  |
| **[An Adaptive Purification Controller for Quantum Networks: Dynamic Protocol Selection and Multipartite Distillation](https://arxiv.org/abs/2601.18351v2)** | 2026-01-27 | <details><summary>Show</summary><p>Efficient entanglement distribution is the cornerstone of the Quantum Internet. However, physical link parameters such as photon loss, memory coherence time, and gate error rates fluctuate dynamically, rendering static purification strategies suboptimal. In this paper, we propose an Adaptive Purification Controller (APC) that autonomously optimizes the entanglement distillation sequence to maximize the "goodput," the rate of delivered pairs meeting a strict fidelity threshold. By treating protocol selection as a resource allocation problem, the APC dynamically switches between purification depths and protocol families (e.g., BBPSSW vs. DEJMPS) to navigate the trade-off between generation rate and state quality. Using a dynamic programming planner with Pareto pruning, simulation results demonstrate that our approach eliminates the "fidelity cliffs" inherent in static protocols and prevents resource wastage in high-noise regimes. Furthermore, we extend the controller to heterogeneous scenarios, demonstrating robustness for both multipartite GHZ state generation and continuous variable systems using effective noiseless linear amplification models. We benchmark its computational overhead, confirming real-time feasibility with decision latencies in the millisecond range per link.</p></details> |  |
| **[Revisiting Parameter Server in LLM Post-Training](https://arxiv.org/abs/2601.19362v1)** | 2026-01-27 | <details><summary>Show</summary><p>Modern data parallel (DP) training favors collective communication over parameter servers (PS) for its simplicity and efficiency under balanced workloads. However, the balanced workload assumption no longer holds in large language model (LLM) post-training due to the high variance in sequence lengths. Under imbalanced workloads, collective communication creates synchronization barriers, leading to under-utilization of devices with smaller workloads. This change in training dynamics calls for a revisit of the PS paradigm for its robustness to such imbalance. We propose \textbf{On-Demand Communication (ODC)}, which adapts PS into Fully Sharded Data Parallel (FSDP) by replacing collective all-gather and reduce-scatter with direct point-to-point communication. Compared to FSDP, ODC reduces the synchronization barrier from once per layer to once per minibatch and decouples the workload on each device so that faster workers are not stalled. It also enables simpler and more effective load balancing at the minibatch level. Across diverse LLM post-training tasks, ODC consistently improves device utilization and training throughput, achieving up to a 36\% speedup over standard FSDP. These results demonstrate that ODC is a superior fit for the prevalent imbalanced workloads in LLM post-training. Our implementation of ODC and integration with FSDP is open-sourced at https://github.com/sail-sg/odc.</p></details> | Accepted in ICLR'26 |
| **[Peformance Isolation for Inference Processes in Edge GPU Systems](https://arxiv.org/abs/2601.07600v2)** | 2026-01-27 | <details><summary>Show</summary><p>This work analyzes the main isolation mechanisms available in modern NVIDIA GPUs: MPS, MIG, and the recent Green Contexts, to ensure predictable inference time in safety-critical applications using deep learning models. The experimental methodology includes performance tests, evaluation of partitioning impact, and analysis of temporal isolation between processes, considering both the NVIDIA A100 and Jetson Orin platforms. It is observed that MIG provides a high level of isolation. At the same time, Green Contexts represent a promising alternative for edge devices by enabling fine-grained SM allocation with low overhead, albeit without memory isolation. The study also identifies current limitations and outlines potential research directions to improve temporal predictability in shared GPUs.</p></details> |  |
| **[BugLens: Leveraging Bisection for Lightweight Compiler Bug Deduplication](https://arxiv.org/abs/2506.23281v2)** | 2026-01-27 | <details><summary>Show</summary><p>Random testing has proven to be an effective technique for compiler validation. However, the debugging of bugs identified through random testing presents a significant challenge due to the frequent occurrence of duplicate test programs that expose identical compiler bugs. The process to identify duplicates is a practical research problem known as bug deduplication. Prior methodologies for compiler bug deduplication primarily rely on program analysis to extract bug-related features for duplicate identification, which can result in substantial computational overhead and limited generalizability. This paper investigates the feasibility of employing bisection, a standard debugging procedure largely overlooked in prior research on compiler bug deduplication, for this purpose. Our study demonstrates that the utilization of bisection to locate failure-inducing commits provides a valuable criterion for deduplication, albeit one that requires supplementary techniques for more accurate identification. Building on these results, we introduce BugLens, a novel deduplication method that primarily uses bisection, enhanced by the identification of bug-triggering optimizations to minimize false negatives. Empirical evaluations conducted on four real-world datasets demonstrate that BugLens significantly outperforms the state-of-the-art analysis-based methodologies Tamer and D3 by saving an average of 26.98% and 9.64% human effort to identify the same number of distinct bugs. Given the inherent simplicity and generalizability of bisection, it presents a highly practical solution for compiler bug deduplication in real-world applications.</p></details> |  |
| **[Non-Asymptotic Performance Analysis of DOA Estimation Based on Real-Valued Root-MUSIC](https://arxiv.org/abs/2509.01999v3)** | 2026-01-27 | <details><summary>Show</summary><p>This paper presents a systematic theoretical performance analysis of the Real-Valued root-MUSIC (RV-root-MUSIC) algorithm under non-asymptotic conditions. A well-known limitation of RV-root-MUSIC is the estimation ambiguity caused by mirror roots, which are typically suppressed using conventional beamforming (CBF). By leveraging the equivalent subspace constructed through the conjugate extension method and exploiting the equivalence of perturbations for true and mirror roots, this work provides a comprehensive study of three key aspects: noise subspace perturbation, true-root perturbation, and mirror-root perturbation. A statistical model is established, and generalized perturbation expressions are derived. Monte Carlo simulations confirm the correctness and effectiveness of the theoretical results. The analysis provides a rigorous foundation for parameter optimization in Direction-of-Arrival (DOA) estimation, with applications in radar, wireless communications, and intelligent sensing.</p></details> | <details><summary>Accep...</summary><p>Accepted to ICASSP 2026</p></details> |
| **[HybridFlow: Resource-Adaptive Subtask Routing for Efficient Edge-Cloud LLM Inference](https://arxiv.org/abs/2512.22137v3)** | 2026-01-27 | <details><summary>Show</summary><p>Edge-cloud collaborative inference is becoming a practical necessity for LLM-powered edge devices: on-device models often cannot afford the required reasoning capability, while cloud-only inference could be prohibitively costly and slow under strict latency and token/API budgets. However, existing edge-cloud collaboration methods often route per query or fixed steps simply based-on the estimated difficulty. Such coarse and static heuristics overlook subtask dependencies, missing opportunities for parallel execution and budget-adaptive routing. To this end, we propose \textbf{HybridFlow}, a resource-adaptive edge-cloud inference framework that (i) builds a dependency-aware DAG for each query and executes newly unlocked subtasks in parallel, reducing end-to-end latency; (ii) routes each subtask online to the edge or cloud via a learned benefit--cost utility model that dynamically trades accuracy gains against token/API and latency budgets, thereby reducing unnecessary cloud usage while preserving reasoning quality. Across GPQA, MMLU-Pro, AIME24, and LiveBench-Reasoning, HybridFlow improves the cost-accuracy trade-off, reducing latency and cloud API usage while maintaining competitive accuracy against strong structured reasoning baselines.</p></details> |  |

